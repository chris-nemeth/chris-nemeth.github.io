<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Gaussian Processes in Julia | Chris Nemeth</title>
<meta name="keywords" content="Gaussian processes, julia">
<meta name="description" content="This repository contains a Julia package for Gaussian process models.">
<meta name="author" content="Jamie Fairbrother,&thinsp;Christopher Nemeth,&thinsp;Maxime Rischard,&thinsp;Johanni Brea,&thinsp;Thomas Pinder">
<link rel="canonical" href="https://chris-nemeth.github.io/software/gaussianprocesses-jl/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.e690afcd5c523330d5c8b4d746eb158361600a015e99518d4d246a6ccab0cc19.css" integrity="sha256-5pCvzVxSMzDVyLTXRusVg2FgCgFemVGNTSRqbMqwzBk=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://chris-nemeth.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://chris-nemeth.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://chris-nemeth.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://chris-nemeth.github.io/apple-touch-icon.png">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://chris-nemeth.github.io/software/gaussianprocesses-jl/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript><meta property="og:title" content="Gaussian Processes in Julia" />
<meta property="og:description" content="This repository contains a Julia package for Gaussian process models." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://chris-nemeth.github.io/software/gaussianprocesses-jl/" />
<meta property="og:image" content="https://chris-nemeth.github.io/poisson_gp.png" /><meta property="article:section" content="software" />
<meta property="article:published_time" content="2024-08-07T00:00:00+00:00" />
<meta property="article:modified_time" content="2024-08-07T00:00:00+00:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://chris-nemeth.github.io/poisson_gp.png" />
<meta name="twitter:title" content="Gaussian Processes in Julia"/>
<meta name="twitter:description" content="This repository contains a Julia package for Gaussian process models."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Data",
      "item": "https://chris-nemeth.github.io/software/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Gaussian Processes in Julia",
      "item": "https://chris-nemeth.github.io/software/gaussianprocesses-jl/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Gaussian Processes in Julia",
  "name": "Gaussian Processes in Julia",
  "description": "This repository contains a Julia package for Gaussian process models.",
  "keywords": [
    "Gaussian processes", "julia"
  ],
  "articleBody": "GaussianProcesses.jl A Gaussian Processes package for Julia.\nIf you have any suggestions to improve the package, or if you’ve noticed a bug, then please post an issue for us and we’ll get to it as quickly as we can. Pull requests are also welcome.\nCiting GaussianProcesses.jl To cite GaussianProcesses.jl, please reference the paper . Sample Bibtex is given below:\n@article{fairbrother2022gaussianprocesses, title={GaussianProcesses. jl: A Nonparametric Bayes Package for the Julia Language}, author={Fairbrother, Jamie and Nemeth, Christopher and Rischard, Maxime and Brea, Johanni and Pinder, Thomas}, journal={Journal of Statistical Software}, volume={102}, pages={1--36}, year={2022} } Introduction Gaussian processes are a family of stochastic processes which provide a flexible nonparametric tool for modelling data. A Gaussian Process places a prior over functions, and can be described as an infinite dimensional generalisation of a multivariate Normal distribution. Moreover, the joint distribution of any finite collection of points is a multivariate Normal. This process can be fully characterised by its mean and covariance functions, where the mean of any point in the process is described by the mean function and the covariance between any two observations is specified by the kernel. Given a set of observed real-valued points over a space, the Gaussian Process is used to make inference on the values at the remaining points in the space.\nFor an extensive review of Gaussian Processes there is an excellent book Gaussian Processes for Machine Learning by Rasmussen and Williams, (2006).\nInstallation GaussianProcesses.jl requires Julia version 0.7 or above. To install GaussianProcesses.jl run the following command inside a Julia session:\njulia\u003e using Pkg julia\u003e Pkg.add(\"GaussianProcesses\") Functionality The package allows the user to fit exact Gaussian process models when the observations are Gaussian distributed about the latent function. In the case where the observations are non-Gaussian, the posterior distribution of the latent function is intractable. The package allows for Monte Carlo sampling from the posterior.\nThe main function of the package is GP, which fits the Gaussian process\ngp = GP(x, y, mean, kernel) gp = GP(x, y, mean, kernel, likelihood) for Gaussian and non-Gaussian data respectively.\nThe package has a number of mean, kernel and likelihood functions available. See the documentation for further details.\nInference The parameters of the model can be estimated by maximizing the log-likelihood (where the latent function is integrated out) using the optimize! function, or in the case of non-Gaussian data, an mcmc function is available, utilizing the Hamiltonian Monte Carlo sampler. In addition to a HMC sampler, it is possible to sample from the posterior using an elliptical slice sampler, provided that the data exhibits a Gaussian likelihood. Finally, for fast, yet approximate inference in the case of Poisson data, a variational approximation can be used to infer the model parameters and latent function values.\noptimize!(gp) # Find parameters which maximize the log-likelihood mcmc(gp) # Sample from the GP posterior ess(gp) # Sample from the GP posterior using an elliptical slice sampler vi(gp) # Create a variational approximation See the notebooks for examples of the functions used in the package.\nDocumentation Documentation is accessible in the Julia REPL in help mode. Help mode can be started by typing ‘?’ at the prompt.\njulia\u003e ?GP search: GP GPE GPMC GPBase gperm log1p getpid getproperty MissingException GP(x, y, mean::Mean, kernel::Kernel[, logNoise::Float64=-2.0]) Fit a Gaussian process that is defined by its mean, its kernel, and the logarithm logNoise of the standard deviation of its observation noise to a set of training points x and y. See also: GPE ──────────────────────────────────────────────────────────────────────────── GP(x, y, mean::Mean, kernel::Kernel, lik::Likelihood) Fit a Gaussian process that is defined by its mean, its kernel, and its likelihood function lik to a set of training points x and y. See also: GPA Alternatively, online documentation and is under development.\nNotebooks Sample code is available from the notebooks .\nRelated packages GeoStats - High-performance implementations of geostatistical algorithms for the Julia programming language. This package is in its initial development, and currently only contains Kriging estimation methods. More features will be added as the Julia type system matures.\nScikitLearn This package also supports the ScikitLearn interface. ScikitLearn provides many tools for machine learning such as hyperparameter tuning and cross-validation. See here for an example of its usage with this package.\n",
  "wordCount" : "696",
  "inLanguage": "en",
  "image":"https://chris-nemeth.github.io/poisson_gp.png","datePublished": "2024-08-07T00:00:00Z",
  "dateModified": "2024-08-07T00:00:00Z",
  "author":[{
    "@type": "Person",
    "name": "Jamie Fairbrother"
  }, {
    "@type": "Person",
    "name": "Christopher Nemeth"
  }, {
    "@type": "Person",
    "name": "Maxime Rischard"
  }, {
    "@type": "Person",
    "name": "Johanni Brea"
  }, {
    "@type": "Person",
    "name": "Thomas Pinder"
  }],
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://chris-nemeth.github.io/software/gaussianprocesses-jl/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Chris Nemeth",
    "logo": {
      "@type": "ImageObject",
      "url": "https://chris-nemeth.github.io/favicon.ico"
    }
  }
}
</script>



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" integrity="sha384-wcIxkf4k558AjM3Yz3BBFQUbk/zgIYC2R0QpeeYb+TwlBVMrlgLqwRjRtGZiK7ww" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.js" integrity="sha384-hIoBPJpTUs74ddyc4bFZSM1TVlQDA60VBbJS0oA934VSz82sBx1X7kSx2ATBDIyd" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/contrib/auto-render.min.js" integrity="sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk" crossorigin="anonymous"
  onload="renderMathInElement(document.body);"></script>

<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          delimiters: [
            {left: '$$', right: '$$', display: true},
            {left: '$', right: '$', display: false},
            {left: "\\begin{equation}", right: "\\end{equation}", display: true},
            {left: "\\begin{equation*}", right: "\\end{equation*}", display: true},
            {left: "\\begin{align}", right: "\\end{align}", display: true},
            {left: "\\begin{align*}", right: "\\end{align*}", display: true},
            {left: "\\begin{alignat}", right: "\\end{alignat}", display: true},
            {left: "\\begin{gather}", right: "\\end{gather}", display: true},
            {left: "\\begin{CD}", right: "\\end{CD}", display: true},
          ],
          throwOnError : false
        });
    });
</script>
 


</head>

<body class="" id="top">

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://chris-nemeth.github.io/" accesskey="h" title="Chris Nemeth">
                <img src="https://chris-nemeth.github.io/favicon.ico" alt="" aria-label="logo"
                    height="18"
                    width="18">Chris Nemeth</a>
            <div class="logo-switches">
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://chris-nemeth.github.io/papers/" title="Papers">
                    <span>Papers</span>
                </a>
            </li>
            <li>
                <a href="https://chris-nemeth.github.io/code_and_software/" title="Code">
                    <span>Code</span>
                </a>
            </li>
            <li>
                <a href="https://chris-nemeth.github.io/software/" title="Software">
                    <span>Software</span>
                </a>
            </li>
            <li>
                <a href="https://chris-nemeth.github.io/books/" title="Books">
                    <span>Books</span>
                </a>
            </li>
            <li>
                <a href="https://chris-nemeth.github.io/research_group/" title="Group">
                    <span>Group</span>
                </a>
            </li>
        </ul>
    </nav>
</header>

    <main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Gaussian Processes in Julia
    </h1>
    <div class="post-meta"><span title='2024-08-07 00:00:00 +0000 UTC'>August 2024</span>&nbsp;&middot;&nbsp;Jamie Fairbrother,&thinsp;Christopher Nemeth,&thinsp;Maxime Rischard,&thinsp;Johanni Brea,&thinsp;Thomas Pinder&nbsp;&middot;&nbsp;<a href="https://github.com/STOR-i/GaussianProcesses.jl" rel="noopener noreferrer" target="_blank">GitHub repository</a>

</div>
  </header> <div class="toc">
    <details  open>
        <summary accesskey="c">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><nav id="TableOfContents">
  <ul>
    <li><a href="#citing-gaussianprocessesjl">Citing GaussianProcesses.jl</a></li>
    <li><a href="#introduction">Introduction</a></li>
    <li><a href="#installation">Installation</a></li>
    <li><a href="#functionality">Functionality</a></li>
    <li><a href="#documentation">Documentation</a></li>
    <li><a href="#notebooks">Notebooks</a></li>
    <li><a href="#related-packages">Related packages</a></li>
    <li><a href="#scikitlearn">ScikitLearn</a></li>
  </ul>
</nav>
        </div>
    </details>
</div>

  <div class="post-content"><h1 id="gaussianprocessesjl">GaussianProcesses.jl<a hidden class="anchor" aria-hidden="true" href="#gaussianprocessesjl">#</a></h1>
<p>A Gaussian Processes package for Julia.</p>
<p>If you have any suggestions to improve the package, or if you&rsquo;ve noticed a bug, then please post an <a href="https://github.com/STOR-i/GaussianProcesses.jl/issues/new" target="_blank">issue</a>
 for us and we&rsquo;ll get to it as quickly as we can. Pull requests are also welcome.</p>
<hr>
<h2 id="citing-gaussianprocessesjl">Citing GaussianProcesses.jl<a hidden class="anchor" aria-hidden="true" href="#citing-gaussianprocessesjl">#</a></h2>
<p>To cite GaussianProcesses.jl, please reference the <a href="http://statistik-jstat.uibk.ac.at/article/view/v102i01" target="_blank">paper</a>
. Sample Bibtex is given below:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bibtex" data-lang="bibtex"><span style="display:flex;"><span><span style="color:#0a0;text-decoration:underline">@article</span>{fairbrother2022gaussianprocesses,
</span></span><span style="display:flex;"><span>  <span style="color:#1e90ff">title</span>=<span style="color:#a50">{GaussianProcesses. jl: A Nonparametric Bayes Package for the Julia Language}</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#1e90ff">author</span>=<span style="color:#a50">{Fairbrother, Jamie and Nemeth, Christopher and Rischard, Maxime and Brea, Johanni and Pinder, Thomas}</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#1e90ff">journal</span>=<span style="color:#a50">{Journal of Statistical Software}</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#1e90ff">volume</span>=<span style="color:#a50">{102}</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#1e90ff">pages</span>=<span style="color:#a50">{1--36}</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#1e90ff">year</span>=<span style="color:#a50">{2022}</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><hr>
<h2 id="introduction">Introduction<a hidden class="anchor" aria-hidden="true" href="#introduction">#</a></h2>
<p>Gaussian processes are a family of stochastic processes which provide a flexible nonparametric tool for modelling data. A Gaussian Process places a prior over functions, and can be described as an infinite dimensional generalisation of a multivariate Normal distribution. Moreover, the joint distribution of any finite collection of points is a multivariate Normal. This process can be fully characterised by its mean and covariance functions, where the mean of any point in the process is described by the <em>mean function</em> and the covariance between any two observations is specified by the <em>kernel</em>. Given a set of observed real-valued points over a space, the Gaussian Process is used to make inference on the values at the remaining points in the space.</p>
<p>For an extensive review of Gaussian Processes there is an excellent book <a href="http://www.gaussianprocess.org/gpml/chapters/RW.pdf" target="_blank">Gaussian Processes for Machine Learning</a>
 by Rasmussen and Williams, (2006).</p>
<hr>
<h2 id="installation">Installation<a hidden class="anchor" aria-hidden="true" href="#installation">#</a></h2>
<p>GaussianProcesses.jl requires Julia version 0.7 or above. To install GaussianProcesses.jl run the following command inside a Julia session:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-julia" data-lang="julia"><span style="display:flex;"><span>julia&gt; <span style="color:#00a">using</span> Pkg
</span></span><span style="display:flex;"><span>julia&gt; Pkg.add(<span style="color:#a50">&#34;GaussianProcesses&#34;</span>)
</span></span></code></pre></div><hr>
<h2 id="functionality">Functionality<a hidden class="anchor" aria-hidden="true" href="#functionality">#</a></h2>
<p>The package allows the user to fit exact <strong>Gaussian process</strong> models when the observations are Gaussian distributed about the latent function. In the case where the <em>observations are non-Gaussian</em>, the posterior distribution of the latent function is intractable. The package allows for Monte Carlo sampling from the posterior.</p>
<p>The main function of the package is <code>GP</code>, which fits the Gaussian process</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-julia" data-lang="julia"><span style="display:flex;"><span>gp = GP(x, y, mean, kernel)
</span></span><span style="display:flex;"><span>gp = GP(x, y, mean, kernel, likelihood)
</span></span></code></pre></div><p>for Gaussian and non-Gaussian data respectively.</p>
<p>The package has a number of <em>mean</em>, <em>kernel</em> and <em>likelihood</em> functions available. See the documentation for further details.</p>
<hr>
<h3 id="inference">Inference<a hidden class="anchor" aria-hidden="true" href="#inference">#</a></h3>
<p>The parameters of the model can be estimated by maximizing the log-likelihood (where the latent function is integrated out) using the <code>optimize!</code> function, or in the case of <em>non-Gaussian data</em>, an <code>mcmc</code> function is available, utilizing the Hamiltonian Monte Carlo sampler. In addition to a HMC sampler, it is possible to sample from the posterior using an elliptical slice sampler, provided that the data exhibits a Gaussian likelihood. Finally, for fast, yet approximate inference in the case of Poisson data, a variational approximation can be used to infer the model parameters and latent function values.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-julia" data-lang="julia"><span style="display:flex;"><span>optimize!(gp)    <span style="color:#aaa;font-style:italic"># Find parameters which maximize the log-likelihood</span>
</span></span><span style="display:flex;"><span>mcmc(gp)         <span style="color:#aaa;font-style:italic"># Sample from the GP posterior</span>
</span></span><span style="display:flex;"><span>ess(gp)          <span style="color:#aaa;font-style:italic"># Sample from the GP posterior using an elliptical slice sampler</span>
</span></span><span style="display:flex;"><span>vi(gp)           <span style="color:#aaa;font-style:italic"># Create a variational approximation</span>
</span></span></code></pre></div><p>See the <a href="https://github.com/STOR-i/GaussianProcesses.jl/tree/master/notebooks" target="_blank">notebooks</a>
 for examples of the functions used in the package.</p>
<hr>
<h2 id="documentation">Documentation<a hidden class="anchor" aria-hidden="true" href="#documentation">#</a></h2>
<p>Documentation is accessible in the Julia REPL in help mode. Help mode can be started by typing &lsquo;?&rsquo; at the prompt.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>julia&gt; ?GP
</span></span><span style="display:flex;"><span>search: GP GPE GPMC GPBase gperm log1p getpid getproperty MissingException
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  GP(x, y, mean::Mean, kernel::Kernel[, logNoise::Float64=-2.0])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  Fit a Gaussian process that is defined by its mean, its kernel, and the
</span></span><span style="display:flex;"><span>  logarithm logNoise of the standard deviation of its observation noise to a
</span></span><span style="display:flex;"><span>  set of training points x and y.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  See also: GPE
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  ────────────────────────────────────────────────────────────────────────────
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  GP(x, y, mean::Mean, kernel::Kernel, lik::Likelihood)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  Fit a Gaussian process that is defined by its mean, its kernel, and its
</span></span><span style="display:flex;"><span>  likelihood function lik to a set of training points x and y.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  See also: GPA
</span></span></code></pre></div><p>Alternatively, <a href="http://stor-i.github.io/GaussianProcesses.jl/latest/index.html" target="_blank">online documentation</a>
 and is under development.</p>
<hr>
<h2 id="notebooks">Notebooks<a hidden class="anchor" aria-hidden="true" href="#notebooks">#</a></h2>
<p>Sample code is available from the <a href="https://github.com/STOR-i/GaussianProcesses.jl/tree/master/notebooks" target="_blank">notebooks</a>
.</p>
<hr>
<h2 id="related-packages">Related packages<a hidden class="anchor" aria-hidden="true" href="#related-packages">#</a></h2>
<p><a href="https://github.com/juliohm/GeoStats.jl" target="_blank">GeoStats</a>
 - High-performance implementations of geostatistical algorithms for the Julia programming language. This package is in its initial development, and currently only contains Kriging estimation methods. More features will be added as the Julia type system matures.</p>
<h2 id="scikitlearn">ScikitLearn<a hidden class="anchor" aria-hidden="true" href="#scikitlearn">#</a></h2>
<p>This package also supports the <a href="https://github.com/cstjean/ScikitLearn.jl" target="_blank">ScikitLearn</a>
 interface. ScikitLearn provides many tools for machine learning such as hyperparameter tuning and cross-validation. See <a href="https://github.com/cstjean/ScikitLearn.jl/blob/master/examples/Gaussian_Processes_Julia.ipynb" target="_blank">here</a>
 for an example of its usage with this package.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://chris-nemeth.github.io/tags/gaussian-processes/">Gaussian Processes</a></li>
      <li><a href="https://chris-nemeth.github.io/tags/julia/">Julia</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="https://chris-nemeth.github.io/">Chris Nemeth</a></span> ·     
    <span>
    Powered by 
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/pmichaillat/hugo-website/" rel="noopener" target="_blank">a modified version</a>
         of 
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>
</html>
