---
title: "Learning-Rate-Free Stochastic Optimization over Riemannian Manifolds"
date: 2024-07-22
lastmod: 2024-07-22
tags: ["learning-rate-free","optimization","Riemannian manifold"]
author: ["Dan Dodd","Louis Sharrock","Christopher Nemeth"]
description: " "
summary: "International Conference on Machine Learning (ICML)"
editPost:
    URL: "https://openreview.net/forum?id=eY98MVffrD"
    Text: "ICML"

---

---


##### Download

+ [Paper](https://openreview.net/pdf?id=eY98MVffrD)
+ [arXiv](https://arxiv.org/abs/2406.02296)
+ [Code](https://github.com/daniel-dodd/riemannian_dog)



---
##### Abstract
In recent years, interest in gradient-based optimization over Riemannian manifolds has surged. However, a significant challenge lies in the reliance on hyperparameters, especially the learning rate, which requires meticulous tuning by practitioners to ensure convergence at a suitable rate. In this work, we introduce innovative learning-rate-free algorithms for stochastic optimization over Riemannian manifolds, eliminating the need for hand-tuning and providing a more robust and user-friendly approach. We establish high probability convergence guarantees that are optimal, up to logarithmic factors, compared to the best-known optimally tuned rate in the deterministic setting. Our approach is validated through numerical experiments, demonstrating competitive performance against learning-rate-dependent algorithms.

---
##### Citation

Dodd, D., Sharrock, L. and Nemeth, C., Learning-Rate-Free Stochastic Optimization over Riemannian Manifolds. In *Forty-first International Conference on Machine Learning*.


```BibTeX
@inproceedings{doddlearning,
  title={Learning-Rate-Free Stochastic Optimization over Riemannian Manifolds},
  author={Dodd, Daniel and Sharrock, Louis and Nemeth, Christopher},
  booktitle={Forty-first International Conference on Machine Learning}
}
```
